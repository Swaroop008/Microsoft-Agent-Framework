{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh0NzvJfOeFEFdLBFJ6jV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swaroop008/Microsoft-Agent-Framework/blob/master/MAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üì¶ Install Dependencies\n",
        "# ==========================================================\n",
        "!pip install --quiet agent_framework   # Microsoft Agent Framework for AI agents\n",
        "!pip install --quiet --upgrade google-generativeai  # Google Gemini API SDK\n",
        "!pip install --quiet aiohttp  # Async HTTP requests (optional but recommended)"
      ],
      "metadata": {
        "id": "XseGnUAcS_Nm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üß† Import Required Libraries\n",
        "# ==========================================================\n",
        "import asyncio  # For asynchronous programming\n",
        "import google.generativeai as genai  # Google Gemini API\n",
        "from agent_framework import ChatMessage, TextContent, UriContent, Role  # Classes to handle AI messages"
      ],
      "metadata": {
        "id": "euSUHzy0TJjJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üîê Configure Gemini API\n",
        "# ==========================================================\n",
        "genai.configure(api_key=\"AIzaSyCCt8XfCAc35zmrrs0DD4ZUYRbKVQ25bbs\")  # Replace with your actual Gemini API key"
      ],
      "metadata": {
        "id": "ozOe2fBJTbxe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# ü§ñ Define the GeminiAgent Class\n",
        "# ==========================================================\n",
        "class GeminiAgent:\n",
        "    \"\"\"\n",
        "    A wrapper around the Gemini API.\n",
        "    Separates agent behavior (instructions/persona) from the user prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"gemini-2.5-flash\", instructions=None, name=\"GeminiAgent\"):\n",
        "        # Initialize the Gemini model\n",
        "        self.model = genai.GenerativeModel(model_name)\n",
        "        self.instructions = instructions  # Define agent persona or behavior\n",
        "        self.name = name  # Name of the agent\n",
        "\n",
        "    async def run(self, user_prompt):\n",
        "        \"\"\"Combine instructions with user prompt and get a response from Gemini API.\"\"\"\n",
        "\n",
        "        # If the user sends a ChatMessage (text + image)\n",
        "        if isinstance(user_prompt, ChatMessage):\n",
        "            prompt_text = \"\"\n",
        "            for content in user_prompt.contents:\n",
        "                if isinstance(content, TextContent):  # Extract text content\n",
        "                    prompt_text += content.text + \"\\n\"\n",
        "                elif isinstance(content, UriContent):  # Extract image URI\n",
        "                    prompt_text += f\"[Image: {content.uri}]\\n\"\n",
        "        else:\n",
        "            prompt_text = str(user_prompt)  # For plain text prompts\n",
        "\n",
        "        # Combine agent instructions (persona) with user prompt\n",
        "        final_prompt = (self.instructions + \"\\n\\n\" if self.instructions else \"\") + prompt_text\n",
        "\n",
        "        # Call the Gemini API asynchronously\n",
        "        response = await asyncio.to_thread(self.model.generate_content, final_prompt)\n",
        "        return response\n"
      ],
      "metadata": {
        "id": "rPJDdE21TiEZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üé≠ Example 1 ‚Äî FunnyBot (Comedian Persona)\n",
        "# ==========================================================\n",
        "funny_agent = GeminiAgent(\n",
        "    instructions=\"You are a witty comedian with great humour.\",\n",
        "    name=\"FunnyBot\"\n",
        ")\n",
        "\n",
        "async def example_text():\n",
        "    user_prompt = \"Tell me a short joke about AI and pirates.\"\n",
        "    print(\"\\nü§ñ FunnyBot (Plain Text Prompt):\\n\")\n",
        "    result = await funny_agent.run(user_prompt)\n",
        "    # Print AI response text if available\n",
        "    print(result.text if hasattr(result, \"text\") else result)\n",
        "\n",
        "await example_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "gC_kIeRcTlDZ",
        "outputId": "f0ebafb4-5c3d-43ee-c398-ab0f0870c6a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ FunnyBot (Plain Text Prompt):\n",
            "\n",
            "Why did the pirate captain fire his AI first mate?\n",
            "\n",
            "Because every time he said, \"Aye, aye, Cap'n!\" the AI kept correcting him: \"Actually, it's spelled A.I., Captain.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üñºÔ∏è Example 2 ‚Äî AnalystBot (Observational Persona)\n",
        "# ==========================================================\n",
        "analyst_agent = GeminiAgent(\n",
        "    instructions=\"You are an observational and analytical AI, making clever comments on images.\",\n",
        "    name=\"AnalystBot\"\n",
        ")\n",
        "\n",
        "# Create a message containing both text and an image\n",
        "user_message = ChatMessage(\n",
        "    role=Role.USER,  # Message from user\n",
        "    contents=[\n",
        "        TextContent(text=\"Estimate the number of people in this image and make a clever joke about it:\"),\n",
        "        UriContent(\n",
        "            uri=\"https://static1.bigstockphoto.com/4/1/2/large1500/21499049.jpg\",  # Image URL\n",
        "            media_type=\"image/jpeg\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "async def example_image():\n",
        "    print(\"\\nü§ñ AnalystBot (Image + Text Message):\\n\")\n",
        "    result = await analyst_agent.run(user_message)\n",
        "    # Print AI response text if available\n",
        "    print(result.text if hasattr(result, \"text\") else result)\n",
        "\n",
        "await example_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ZlntYZQwTsK1",
        "outputId": "afc6103e-7eb3-4427-8896-eaf7ac62974c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ AnalystBot (Image + Text Message):\n",
            "\n",
            "I'd estimate there are roughly **4,000** people here.\n",
            "\n",
            "That's enough people to make getting separated from your friends feel less like an accident and more like a planned wilderness survival challenge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# üé® Example 3 ‚Äî PoetBot (Creative Persona)\n",
        "# ==========================================================\n",
        "poet_agent = GeminiAgent(\n",
        "    instructions=\"You are a creative poet AI, writing imaginative and poetic responses.\",\n",
        "    name=\"PoetBot\"\n",
        ")\n",
        "\n",
        "async def example_poem():\n",
        "    user_prompt = \"Write a short poem about a sunset in the city.\"\n",
        "    print(\"\\nü§ñ PoetBot (Plain Text Prompt):\\n\")\n",
        "    result = await poet_agent.run(user_prompt)\n",
        "    # Print AI response text if available\n",
        "    print(result.text if hasattr(result, \"text\") else result)\n",
        "\n",
        "await example_poem()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "mm28_8FUT0aV",
        "outputId": "23346603-0268-4c6d-bcff-4bc97b6c2b98"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ PoetBot (Plain Text Prompt):\n",
            "\n",
            "The sun, a fiery painter's brush,\n",
            "Streaks amber on the towers tall.\n",
            "Each pane of glass, a burning hush,\n",
            "Reflects the day's last, gilded fall.\n",
            "Then violet dusts the city wall.\n"
          ]
        }
      ]
    }
  ]
}